{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "812c60f1",
      "metadata": {
        "id": "812c60f1"
      },
      "source": [
        "# 한정된 데이터로 Transfer learning 적용해보기 "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05473cc0",
      "metadata": {
        "id": "05473cc0"
      },
      "source": [
        "## 1. CT이미지 데이터셋 살펴보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11b1244e",
      "metadata": {
        "id": "11b1244e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa3eba5f",
      "metadata": {
        "id": "aa3eba5f",
        "outputId": "41d79873-c8f7-4fb2-b3cb-5fdda5d87547"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>MaskId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID00007637202177411956430_0.jpg</td>\n",
              "      <td>ID00007637202177411956430_mask_0.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID00007637202177411956430_1.jpg</td>\n",
              "      <td>ID00007637202177411956430_mask_1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID00007637202177411956430_2.jpg</td>\n",
              "      <td>ID00007637202177411956430_mask_2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID00007637202177411956430_3.jpg</td>\n",
              "      <td>ID00007637202177411956430_mask_3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID00007637202177411956430_4.jpg</td>\n",
              "      <td>ID00007637202177411956430_mask_4.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           ImageId                                MaskId\n",
              "0  ID00007637202177411956430_0.jpg  ID00007637202177411956430_mask_0.jpg\n",
              "1  ID00007637202177411956430_1.jpg  ID00007637202177411956430_mask_1.jpg\n",
              "2  ID00007637202177411956430_2.jpg  ID00007637202177411956430_mask_2.jpg\n",
              "3  ID00007637202177411956430_3.jpg  ID00007637202177411956430_mask_3.jpg\n",
              "4  ID00007637202177411956430_4.jpg  ID00007637202177411956430_mask_4.jpg"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_dir = \"../DATASET/Segmentation/\"\n",
        "data_df = pd.read_csv(os.path.join(data_dir, \"train.csv\"))\n",
        "data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13648618",
      "metadata": {
        "id": "13648618"
      },
      "outputs": [],
      "source": [
        "def extract_client_id(x):\n",
        "    return x.split(\"_\")[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dd46171",
      "metadata": {
        "id": "2dd46171",
        "outputId": "4c0a98f1-dd9b-4478-c86a-4000251a3d76"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>MaskId</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID00007637202177411956430_0.jpg</td>\n",
              "      <td>ID00007637202177411956430_mask_0.jpg</td>\n",
              "      <td>ID00007637202177411956430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID00007637202177411956430_1.jpg</td>\n",
              "      <td>ID00007637202177411956430_mask_1.jpg</td>\n",
              "      <td>ID00007637202177411956430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID00007637202177411956430_2.jpg</td>\n",
              "      <td>ID00007637202177411956430_mask_2.jpg</td>\n",
              "      <td>ID00007637202177411956430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID00007637202177411956430_3.jpg</td>\n",
              "      <td>ID00007637202177411956430_mask_3.jpg</td>\n",
              "      <td>ID00007637202177411956430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID00007637202177411956430_4.jpg</td>\n",
              "      <td>ID00007637202177411956430_mask_4.jpg</td>\n",
              "      <td>ID00007637202177411956430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16703</th>\n",
              "      <td>ID00426637202313170790466_403.jpg</td>\n",
              "      <td>ID00426637202313170790466_mask_403.jpg</td>\n",
              "      <td>ID00426637202313170790466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16704</th>\n",
              "      <td>ID00426637202313170790466_404.jpg</td>\n",
              "      <td>ID00426637202313170790466_mask_404.jpg</td>\n",
              "      <td>ID00426637202313170790466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16705</th>\n",
              "      <td>ID00426637202313170790466_405.jpg</td>\n",
              "      <td>ID00426637202313170790466_mask_405.jpg</td>\n",
              "      <td>ID00426637202313170790466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16706</th>\n",
              "      <td>ID00426637202313170790466_406.jpg</td>\n",
              "      <td>ID00426637202313170790466_mask_406.jpg</td>\n",
              "      <td>ID00426637202313170790466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16707</th>\n",
              "      <td>ID00426637202313170790466_407.jpg</td>\n",
              "      <td>ID00426637202313170790466_mask_407.jpg</td>\n",
              "      <td>ID00426637202313170790466</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16708 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 ImageId  \\\n",
              "0        ID00007637202177411956430_0.jpg   \n",
              "1        ID00007637202177411956430_1.jpg   \n",
              "2        ID00007637202177411956430_2.jpg   \n",
              "3        ID00007637202177411956430_3.jpg   \n",
              "4        ID00007637202177411956430_4.jpg   \n",
              "...                                  ...   \n",
              "16703  ID00426637202313170790466_403.jpg   \n",
              "16704  ID00426637202313170790466_404.jpg   \n",
              "16705  ID00426637202313170790466_405.jpg   \n",
              "16706  ID00426637202313170790466_406.jpg   \n",
              "16707  ID00426637202313170790466_407.jpg   \n",
              "\n",
              "                                       MaskId                         Id  \n",
              "0        ID00007637202177411956430_mask_0.jpg  ID00007637202177411956430  \n",
              "1        ID00007637202177411956430_mask_1.jpg  ID00007637202177411956430  \n",
              "2        ID00007637202177411956430_mask_2.jpg  ID00007637202177411956430  \n",
              "3        ID00007637202177411956430_mask_3.jpg  ID00007637202177411956430  \n",
              "4        ID00007637202177411956430_mask_4.jpg  ID00007637202177411956430  \n",
              "...                                       ...                        ...  \n",
              "16703  ID00426637202313170790466_mask_403.jpg  ID00426637202313170790466  \n",
              "16704  ID00426637202313170790466_mask_404.jpg  ID00426637202313170790466  \n",
              "16705  ID00426637202313170790466_mask_405.jpg  ID00426637202313170790466  \n",
              "16706  ID00426637202313170790466_mask_406.jpg  ID00426637202313170790466  \n",
              "16707  ID00426637202313170790466_mask_407.jpg  ID00426637202313170790466  \n",
              "\n",
              "[16708 rows x 3 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_df[\"Id\"] = data_df.ImageId.apply(lambda x:extract_client_id(x))\n",
        "data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07063733",
      "metadata": {
        "id": "07063733"
      },
      "outputs": [],
      "source": [
        "def get_client_data(data_df, index):\n",
        "    client_ids = np.unique(data_df.Id.values)\n",
        "    client_id = client_ids[index]\n",
        "    client_data = data_df[data_df.Id == client_id]\n",
        "    image_files = list(client_data[\"ImageId\"])\n",
        "    mask_files = list(client_data[\"MaskId\"])\n",
        "    return client_id, image_files, mask_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a87ab0b6",
      "metadata": {
        "id": "a87ab0b6"
      },
      "outputs": [],
      "source": [
        "regions = [\"background\", \"trachea\", \"heart\", \"lung\"]\n",
        "colors = ((0,0,0), (255, 0, 0), (0, 255, 0), (0, 0, 255))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d289deb",
      "metadata": {
        "id": "8d289deb"
      },
      "outputs": [],
      "source": [
        "index = 50\n",
        "client_id, image_files, mask_files = get_client_data(data_df, index)\n",
        "\n",
        "canvas = np.zeros(shape=(512, 2*512+50, 3), dtype=np.uint8)\n",
        "for i in range(len(image_files)):\n",
        "    image = cv2.imread(os.path.join(data_dir, \"images\", image_files[i]))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    mask = cv2.imread(os.path.join(data_dir, \"masks\", mask_files[i]))\n",
        "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
        "    thres = 240\n",
        "    mask[mask < thres] = 0\n",
        "    mask[mask >= thres] = 255\n",
        "    \n",
        "    canvas[:, :512, :] = image\n",
        "    canvas[:, 512+50:2*512+50, :] = mask\n",
        "    \n",
        "    text_buff = 410\n",
        "    for j in range(1, len(regions)):\n",
        "        cv2.putText(canvas, f'{regions[j].upper()}', (900, text_buff), \n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, colors[j], 2)\n",
        "        text_buff += 40\n",
        "    \n",
        "    cv2.imshow('image', canvas)\n",
        "    key = cv2.waitKey(60)\n",
        "    if key == 27:\n",
        "        break\n",
        "    if key == ord('s'):\n",
        "        cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc4124d8",
      "metadata": {
        "id": "cc4124d8"
      },
      "source": [
        "## 2. 데이터셋 구축과 연산을 위한 텐서변환 모듈 작성하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cca3e2b8",
      "metadata": {
        "id": "cca3e2b8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "IMAGE_SIZE = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab918377",
      "metadata": {
        "id": "ab918377"
      },
      "outputs": [],
      "source": [
        "class CT_dataset():\n",
        "    def __init__(self, data_dir, phase, transformer=None):\n",
        "        self.phase = phase\n",
        "        self.images_dir = os.path.join(data_dir, phase, \"images\")\n",
        "        self.masks_dir = os.path.join(data_dir, phase, \"masks\")\n",
        "        self.image_files = [filename for filename in os.listdir(self.images_dir) if filename.endswith(\"jpg\")]\n",
        "        self.mask_files =  [filename for filename in os.listdir(self.masks_dir) if filename.endswith(\"jpg\")]\n",
        "        assert len(self.image_files) == len(self.mask_files)\n",
        "        \n",
        "        self.transformer = transformer\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image = cv2.imread(os.path.join(self.images_dir, self.image_files[index]))\n",
        "        image = cv2.resize(image, dsize=(IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_LINEAR)\n",
        "        mask = cv2.imread(os.path.join(self.masks_dir, self.mask_files[index]))\n",
        "        mask = cv2.resize(mask, dsize=(IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_NEAREST)\n",
        "        \n",
        "        mask[mask < 240] = 0\n",
        "        mask[mask >= 240] = 255\n",
        "        mask = mask / 255.\n",
        "        \n",
        "        mask_H, mask_W, mask_C = mask.shape\n",
        "        background = np.ones(shape=(mask_H, mask_W))\n",
        "        background[mask[..., 0] != 0] = 0\n",
        "        background[mask[..., 1] != 0] = 0\n",
        "        background[mask[..., 2] != 0] = 0\n",
        "        mask = np.concatenate([np.expand_dims(background, axis=-1), mask], axis=-1)\n",
        "        mask = np.argmax(mask, axis=-1, keepdims=False)\n",
        "        \n",
        "        if self.transformer:\n",
        "            image = self.transformer(image)\n",
        "        \n",
        "        target = torch.from_numpy(mask).long()\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9a48a05",
      "metadata": {
        "id": "a9a48a05"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "def build_transformer():\n",
        "    transformer = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    return transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d42f3709",
      "metadata": {
        "id": "d42f3709"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    images = []\n",
        "    targets = []\n",
        "    for a, b in batch:\n",
        "        images.append(a)\n",
        "        targets.append(b)\n",
        "    images = torch.stack(images, dim=0)\n",
        "    targets = torch.stack(targets, dim=0)\n",
        "    return images, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dc6951e",
      "metadata": {
        "id": "6dc6951e"
      },
      "outputs": [],
      "source": [
        "data_dir = \"../DATASET/Segmentation/\"\n",
        "transformer = build_transformer()\n",
        "dset = CT_dataset(data_dir=data_dir, phase=\"train\", transformer=transformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd96ff53",
      "metadata": {
        "id": "cd96ff53",
        "outputId": "4024294f-ccc3-48ec-a122-34d599d2aa58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image shape: torch.Size([3, 224, 224])\n",
            "target shape: torch.Size([224, 224])\n"
          ]
        }
      ],
      "source": [
        "image, target = dset[0]\n",
        "print(f\"image shape: {image.shape}\")\n",
        "print(f\"target shape: {target.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdb60feb",
      "metadata": {
        "id": "bdb60feb"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fafd1fc",
      "metadata": {
        "id": "5fafd1fc"
      },
      "outputs": [],
      "source": [
        "dloader = DataLoader(dset, batch_size=4, shuffle=True, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21bec5ed",
      "metadata": {
        "id": "21bec5ed",
        "outputId": "1a7de6cd-72da-4b8e-eda2-22b9b19b5101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "images shape: torch.Size([4, 3, 224, 224])\n",
            "targets shape: torch.Size([4, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "for index, batch in enumerate(dloader):\n",
        "    images = batch[0]\n",
        "    targets = batch[1]\n",
        "    print(f\"images shape: {images.shape}\")\n",
        "    print(f\"targets shape: {targets.shape}\")\n",
        "    \n",
        "    if index == 0:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd3bf510",
      "metadata": {
        "id": "fd3bf510"
      },
      "outputs": [],
      "source": [
        "def build_dataloader(data_dir, batch_size=4):\n",
        "    transformer = build_transformer()\n",
        "    \n",
        "    dataloaders = {}\n",
        "    train_dataset = CT_dataset(data_dir=data_dir, phase=\"train\", transformer=transformer)\n",
        "    dataloaders[\"train\"] = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "    \n",
        "    val_dataset = CT_dataset(data_dir=data_dir, phase=\"val\", transformer=transformer)\n",
        "    dataloaders[\"val\"] = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "    return dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f66a71ae",
      "metadata": {
        "id": "f66a71ae",
        "outputId": "4dbe8519-0e0a-4241-eb58-de84b5bfcb32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "images shape: torch.Size([4, 3, 224, 224])\n",
            "targets shape: torch.Size([4, 224, 224])\n",
            "images shape: torch.Size([4, 3, 224, 224])\n",
            "targets shape: torch.Size([4, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "data_dir = \"../DATASET/Segmentation/\"\n",
        "dataloaders = build_dataloader(data_dir=data_dir)\n",
        "\n",
        "for phase in [\"train\", \"val\"]:\n",
        "    for index, batch in enumerate(dataloaders[phase]):\n",
        "        images = batch[0]\n",
        "        targets = batch[1]\n",
        "        print(f\"images shape: {images.shape}\")\n",
        "        print(f\"targets shape: {targets.shape}\")\n",
        "        \n",
        "        if index == 0:\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81ee5452",
      "metadata": {
        "id": "81ee5452"
      },
      "source": [
        "## 3. VGG16 Backbone 을 이용한 U-Net 아키텍처 구현해보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70c6e9cd",
      "metadata": {
        "id": "70c6e9cd"
      },
      "outputs": [],
      "source": [
        "def ConvLayer(in_channels, out_channels, kernel_size=3, padding=1):\n",
        "    layers = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "    return layers\n",
        "\n",
        "def UpConvLayer(in_channels, out_channels):\n",
        "    layers = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "    return layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "891e6ef3",
      "metadata": {
        "id": "891e6ef3"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import transforms, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "643fffe5",
      "metadata": {
        "id": "643fffe5"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, pretrained):\n",
        "        super().__init__()\n",
        "        backbone = models.vgg16_bn(pretrained=pretrained).features\n",
        "        self.conv_block1 = nn.Sequential(*backbone[:6])\n",
        "        self.conv_block2 = nn.Sequential(*backbone[6:13])\n",
        "        self.conv_block3 = nn.Sequential(*backbone[13:20])\n",
        "        self.conv_block4 = nn.Sequential(*backbone[20:27])\n",
        "        self.conv_block5 = nn.Sequential(*backbone[27:34], \n",
        "                                         ConvLayer(512, 1024, kernel_size=1, padding=0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        encode_features = []\n",
        "        out = self.conv_block1(x)\n",
        "        encode_features.append(out)\n",
        "        \n",
        "        out = self.conv_block2(out)\n",
        "        encode_features.append(out)\n",
        "        \n",
        "        out = self.conv_block3(out)\n",
        "        encode_features.append(out)\n",
        "        \n",
        "        out = self.conv_block4(out)\n",
        "        encode_features.append(out)\n",
        "        \n",
        "        out = self.conv_block5(out)\n",
        "        return out, encode_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddefcb5b",
      "metadata": {
        "id": "ddefcb5b"
      },
      "outputs": [],
      "source": [
        "encoder = Encoder(pretrained=False)\n",
        "x = torch.randn(1, 3, 224, 224)\n",
        "out, ftrs = encoder(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c258cf0b",
      "metadata": {
        "id": "c258cf0b",
        "outputId": "351cb5c4-ca0a-44ff-cbe0-784a2bb7a11d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64, 224, 224])\n",
            "torch.Size([1, 128, 112, 112])\n",
            "torch.Size([1, 256, 56, 56])\n",
            "torch.Size([1, 512, 28, 28])\n",
            "torch.Size([1, 1024, 14, 14])\n"
          ]
        }
      ],
      "source": [
        "for ftr in ftrs:\n",
        "    print(ftr.shape)\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3abc919b",
      "metadata": {
        "id": "3abc919b"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.upconv_layer1 = UpConvLayer(in_channels=1024, out_channels=512)\n",
        "        self.conv_block1 = ConvLayer(in_channels=512+512, out_channels=512)\n",
        "        \n",
        "        self.upconv_layer2 = UpConvLayer(in_channels=512, out_channels=256)\n",
        "        self.conv_block2 = ConvLayer(in_channels=256+256, out_channels=256)\n",
        "        \n",
        "        self.upconv_layer3 = UpConvLayer(in_channels=256, out_channels=128)\n",
        "        self.conv_block3 = ConvLayer(in_channels=128+128, out_channels=128)\n",
        "        \n",
        "        self.upconv_layer4 = UpConvLayer(in_channels=128, out_channels=64)\n",
        "        self.conv_block4 = ConvLayer(in_channels=64+64, out_channels=64)\n",
        "        \n",
        "    def forward(self, x, encoder_features):\n",
        "        out = self.upconv_layer1(x)\n",
        "        out = torch.cat([out, encoder_features[-1]], dim=1)\n",
        "        out = self.conv_block1(out)\n",
        "        \n",
        "        out = self.upconv_layer2(out)\n",
        "        out = torch.cat([out, encoder_features[-2]], dim=1)\n",
        "        out = self.conv_block2(out)\n",
        "        \n",
        "        out = self.upconv_layer3(out)\n",
        "        out = torch.cat([out, encoder_features[-3]], dim=1)\n",
        "        out = self.conv_block3(out)\n",
        "        \n",
        "        out = self.upconv_layer4(out)\n",
        "        out = torch.cat([out, encoder_features[-4]], dim=1)\n",
        "        out = self.conv_block4(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "211d7254",
      "metadata": {
        "id": "211d7254"
      },
      "outputs": [],
      "source": [
        "encoder = Encoder(pretrained=False)\n",
        "decoder = Decoder()\n",
        "x = torch.randn(1, 3, 224, 224)\n",
        "out, ftrs = encoder(x)\n",
        "out = decoder(out, ftrs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aa089d1",
      "metadata": {
        "id": "2aa089d1",
        "outputId": "16ab8411-1076-4add-c34c-b2f2c255084c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70e1fe93",
      "metadata": {
        "id": "70e1fe93"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(pretrained)\n",
        "        self.decoder = Decoder()\n",
        "        self.head = nn.Conv2d(64, num_classes, kernel_size=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out, encode_features = self.encoder(x)\n",
        "        out = self.decoder(out, encode_features)\n",
        "        out = self.head(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05b6bc48",
      "metadata": {
        "id": "05b6bc48"
      },
      "outputs": [],
      "source": [
        "model = UNet(num_classes=4, pretrained=False)\n",
        "x = torch.randn(1, 3, 224, 224)\n",
        "out = model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f72672f",
      "metadata": {
        "id": "8f72672f",
        "outputId": "56dd8a74-ce35-4626-a315-92bbe4ae7041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31fb2946",
      "metadata": {
        "id": "31fb2946"
      },
      "source": [
        "## 4. Semantic segmentation Loss와 학습코드 작성하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c278cbc",
      "metadata": {
        "id": "0c278cbc"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e5cd719",
      "metadata": {
        "id": "5e5cd719"
      },
      "outputs": [],
      "source": [
        "class UNet_metric():\n",
        "    def __init__(self, num_classes):\n",
        "        self.num_classes = num_classes\n",
        "        self.CE_loss = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "        \n",
        "    def __call__(self, pred, target):\n",
        "        loss1 = self.CE_loss(pred, target)\n",
        "        onehot_pred = F.one_hot(torch.argmax(pred, dim=1), num_classes=self.num_classes).permute(0, 3, 1, 2)\n",
        "        onehot_target = F.one_hot(target, num_classes=self.num_classes).permute(0, 3, 1, 2)\n",
        "        loss2 = self._get_dice_loss(onehot_pred, onehot_target)\n",
        "        loss = loss1 + loss2\n",
        "        \n",
        "        dice_coefficient = self._get_batch_dice_coefficient(onehot_pred, onehot_target)\n",
        "        return loss, dice_coefficient\n",
        "    \n",
        "    def _get_dice_coeffient(self, pred, target):\n",
        "        set_inter = torch.dot(pred.reshape(-1).float(), target.reshape(-1).float())\n",
        "        set_sum = pred.sum() + target.sum()\n",
        "        if set_sum.item() == 0:\n",
        "            set_sum = 2 * set_inter\n",
        "        dice_coeff = (2 * set_inter) / (set_sum + 1e-9)\n",
        "        return dice_coeff\n",
        "    \n",
        "    def _get_multiclass_dice_coefficient(self, pred, target):\n",
        "        dice = 0\n",
        "        for class_index in range(1, self.num_classes):\n",
        "            dice += self._get_dice_coeffient(pred[class_index], target[class_index])\n",
        "        return dice / (self.num_classes - 1)\n",
        "    \n",
        "    def _get_batch_dice_coefficient(self, pred, target):\n",
        "        num_batch = pred.shape[0]\n",
        "        dice = 0\n",
        "        for batch_index in range(num_batch):\n",
        "            dice += self._get_multiclass_dice_coefficient(pred[batch_index], target[batch_index])\n",
        "        return dice / num_batch\n",
        "    \n",
        "    def _get_dice_loss(self, pred, target):\n",
        "        return 1 - self._get_batch_dice_coefficient(pred, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "776c2291",
      "metadata": {
        "id": "776c2291"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(dataloaders, model, criterion, optimizer, device):\n",
        "    losses = {}\n",
        "    dice_coefficients = {}\n",
        "    \n",
        "    for phase in [\"train\", \"val\"]:\n",
        "        running_loss = 0.0\n",
        "        running_dice_coeff = 0.0\n",
        "        \n",
        "        if phase == \"train\":\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "        \n",
        "        for index, batch in enumerate(dataloaders[phase]):\n",
        "            images = batch[0].to(device)\n",
        "            targets = batch[1].to(device)\n",
        "            \n",
        "            with torch.set_grad_enabled(phase == \"train\"):\n",
        "                predictions = model(images)\n",
        "                loss, dice_coefficient = criterion(predictions, targets)\n",
        "                \n",
        "            if phase == \"train\":\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            running_dice_coeff += dice_coefficient.item()\n",
        "\n",
        "            if index == 10: # 10 index * mini_batch 데이터수 만큼 데이터를 한정\n",
        "                break\n",
        "\n",
        "        losses[phase] = running_loss / index\n",
        "        dice_coefficients[phase] = running_dice_coeff / index\n",
        "        \n",
        "    return losses, dice_coefficients"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9f3e4b1",
      "metadata": {
        "id": "f9f3e4b1"
      },
      "source": [
        "## 5. Weight Initialization 과 Transfer learning 모델 비교하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c59a22c0",
      "metadata": {
        "id": "c59a22c0"
      },
      "source": [
        "### 5-1. He initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f386474",
      "metadata": {
        "id": "2f386474"
      },
      "outputs": [],
      "source": [
        "def He_initialization(module):\n",
        "    if isinstance(module, torch.nn.Conv2d):\n",
        "        torch.nn.init.kaiming_normal_(module.weight) # He initialization\n",
        "    elif isinstance(module, torch.nn.BatchNorm2d):\n",
        "        module.weight.data.fill_(1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ff2f52",
      "metadata": {
        "id": "82ff2f52"
      },
      "outputs": [],
      "source": [
        "data_dir = \"../DATASET/Segmentation/\"\n",
        "is_cuda = True\n",
        "\n",
        "NUM_CLASSES = 4\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 12\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() and is_cuda else 'cpu')\n",
        "\n",
        "dataloaders = build_dataloader(data_dir, batch_size=BATCH_SIZE)\n",
        "model = UNet(num_classes=NUM_CLASSES, pretrained=False)\n",
        "model.apply(weight_He_initialization)\n",
        "model = model.to(DEVICE)\n",
        "criterion = UNet_metric(num_classes=NUM_CLASSES)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1338672f",
      "metadata": {
        "scrolled": true,
        "id": "1338672f",
        "outputId": "ef665cae-ae32-4bcc-9389-d2d7b0b75cbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0/30 - Train loss: 2.6626, Val loss: 2.1546, Train dice: 0.0602, Val dice: 0.0487\n",
            "1/30 - Train loss: 2.2176, Val loss: 1.8182, Train dice: 0.0827, Val dice: 0.0539\n",
            "2/30 - Train loss: 1.8437, Val loss: 1.6423, Train dice: 0.1071, Val dice: 0.0701\n",
            "3/30 - Train loss: 1.6344, Val loss: 1.5569, Train dice: 0.1181, Val dice: 0.0787\n",
            "4/30 - Train loss: 1.5175, Val loss: 1.5088, Train dice: 0.1282, Val dice: 0.0859\n",
            "5/30 - Train loss: 1.4379, Val loss: 1.4718, Train dice: 0.1430, Val dice: 0.0956\n",
            "6/30 - Train loss: 1.3755, Val loss: 1.4369, Train dice: 0.1600, Val dice: 0.1087\n",
            "7/30 - Train loss: 1.3221, Val loss: 1.4040, Train dice: 0.1777, Val dice: 0.1227\n",
            "8/30 - Train loss: 1.2756, Val loss: 1.3742, Train dice: 0.1941, Val dice: 0.1362\n",
            "9/30 - Train loss: 1.2354, Val loss: 1.3455, Train dice: 0.2081, Val dice: 0.1501\n",
            "10/30 - Train loss: 1.2003, Val loss: 1.3193, Train dice: 0.2198, Val dice: 0.1629\n",
            "11/30 - Train loss: 1.1700, Val loss: 1.2967, Train dice: 0.2293, Val dice: 0.1736\n",
            "12/30 - Train loss: 1.1438, Val loss: 1.2776, Train dice: 0.2370, Val dice: 0.1825\n",
            "13/30 - Train loss: 1.1211, Val loss: 1.2614, Train dice: 0.2433, Val dice: 0.1897\n",
            "14/30 - Train loss: 1.1011, Val loss: 1.2482, Train dice: 0.2487, Val dice: 0.1953\n",
            "15/30 - Train loss: 1.0839, Val loss: 1.2368, Train dice: 0.2531, Val dice: 0.2002\n",
            "16/30 - Train loss: 1.0686, Val loss: 1.2274, Train dice: 0.2570, Val dice: 0.2040\n",
            "17/30 - Train loss: 1.0551, Val loss: 1.2199, Train dice: 0.2605, Val dice: 0.2070\n",
            "18/30 - Train loss: 1.0431, Val loss: 1.2137, Train dice: 0.2635, Val dice: 0.2095\n",
            "19/30 - Train loss: 1.0323, Val loss: 1.2081, Train dice: 0.2663, Val dice: 0.2116\n",
            "20/30 - Train loss: 1.0228, Val loss: 1.2034, Train dice: 0.2686, Val dice: 0.2134\n",
            "21/30 - Train loss: 1.0143, Val loss: 1.1992, Train dice: 0.2707, Val dice: 0.2151\n",
            "22/30 - Train loss: 1.0066, Val loss: 1.1955, Train dice: 0.2725, Val dice: 0.2166\n",
            "23/30 - Train loss: 0.9996, Val loss: 1.1934, Train dice: 0.2741, Val dice: 0.2173\n",
            "24/30 - Train loss: 0.9933, Val loss: 1.1905, Train dice: 0.2756, Val dice: 0.2185\n",
            "25/30 - Train loss: 0.9875, Val loss: 1.1887, Train dice: 0.2769, Val dice: 0.2191\n",
            "26/30 - Train loss: 0.9821, Val loss: 1.1869, Train dice: 0.2780, Val dice: 0.2199\n",
            "27/30 - Train loss: 0.9771, Val loss: 1.1852, Train dice: 0.2790, Val dice: 0.2206\n",
            "28/30 - Train loss: 0.9726, Val loss: 1.1841, Train dice: 0.2799, Val dice: 0.2210\n",
            "29/30 - Train loss: 0.9683, Val loss: 1.1828, Train dice: 0.2808, Val dice: 0.2216\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "\n",
        "train_loss_def, train_dice_coefficient_def = [], []\n",
        "val_loss_def, val_dice_coefficient_def = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    losses, dice_coefficients = train_one_epoch(dataloaders, model, criterion, optimizer, DEVICE)\n",
        "    train_loss_def.append(losses[\"train\"])\n",
        "    val_loss_def.append(losses[\"val\"])\n",
        "    train_dice_coefficient_def.append(dice_coefficients[\"train\"])\n",
        "    val_dice_coefficient_def.append(dice_coefficients[\"val\"])\n",
        "    \n",
        "    print(f\"{epoch}/{num_epochs} - Train loss: {losses['train']:.4f}, Val loss: {losses['val']:.4f},\" + \\\n",
        "          f\" Train dice: {dice_coefficients['train']:.4f}, Val dice: {dice_coefficients['val']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4018873",
      "metadata": {
        "id": "b4018873"
      },
      "source": [
        "### 5-2. Weight transfer pre-trained on ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f9898d6",
      "metadata": {
        "id": "8f9898d6"
      },
      "outputs": [],
      "source": [
        "data_dir = \"../DATASET/Segmentation/\"\n",
        "is_cuda = True\n",
        "\n",
        "NUM_CLASSES = 4\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 12\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() and is_cuda else 'cpu')\n",
        "\n",
        "dataloaders = build_dataloader(data_dir, batch_size=BATCH_SIZE)\n",
        "model = UNet(num_classes=NUM_CLASSES, pretrained=True)\n",
        "model = model.to(DEVICE)\n",
        "criterion = UNet_metric(num_classes=NUM_CLASSES)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11db5b2e",
      "metadata": {
        "id": "11db5b2e",
        "outputId": "d4cf9248-bacc-4933-b0d3-4fe182efadcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0/30 - Train loss: 2.5675, Val loss: 2.5100, Train dice: 0.0862, Val dice: 0.0715\n",
            "1/30 - Train loss: 2.2184, Val loss: 2.3311, Train dice: 0.0633, Val dice: 0.0004\n",
            "2/30 - Train loss: 1.9612, Val loss: 2.0221, Train dice: 0.0091, Val dice: 0.0000\n",
            "3/30 - Train loss: 1.8069, Val loss: 1.8172, Train dice: 0.0002, Val dice: 0.0000\n",
            "4/30 - Train loss: 1.7273, Val loss: 1.7162, Train dice: 0.0000, Val dice: 0.0000\n",
            "5/30 - Train loss: 1.6795, Val loss: 1.6654, Train dice: 0.0000, Val dice: 0.0000\n",
            "6/30 - Train loss: 1.6404, Val loss: 1.6382, Train dice: 0.0000, Val dice: 0.0000\n",
            "7/30 - Train loss: 1.5991, Val loss: 1.6143, Train dice: 0.0001, Val dice: 0.0000\n",
            "8/30 - Train loss: 1.5501, Val loss: 1.5871, Train dice: 0.0011, Val dice: 0.0001\n",
            "9/30 - Train loss: 1.4713, Val loss: 1.5324, Train dice: 0.0259, Val dice: 0.0046\n",
            "10/30 - Train loss: 1.2950, Val loss: 1.4362, Train dice: 0.1491, Val dice: 0.0668\n",
            "11/30 - Train loss: 1.1583, Val loss: 1.3052, Train dice: 0.2416, Val dice: 0.1700\n",
            "12/30 - Train loss: 1.0877, Val loss: 1.2359, Train dice: 0.2751, Val dice: 0.2107\n",
            "13/30 - Train loss: 1.0420, Val loss: 1.2274, Train dice: 0.2889, Val dice: 0.2327\n",
            "14/30 - Train loss: 1.0140, Val loss: 1.1616, Train dice: 0.2927, Val dice: 0.2502\n",
            "15/30 - Train loss: 0.9862, Val loss: 1.1437, Train dice: 0.2975, Val dice: 0.2567\n",
            "16/30 - Train loss: 0.9675, Val loss: 1.1365, Train dice: 0.2992, Val dice: 0.2563\n",
            "17/30 - Train loss: 0.9523, Val loss: 1.1205, Train dice: 0.3004, Val dice: 0.2594\n",
            "18/30 - Train loss: 0.9399, Val loss: 1.1266, Train dice: 0.3013, Val dice: 0.2566\n",
            "19/30 - Train loss: 0.9314, Val loss: 1.1014, Train dice: 0.3016, Val dice: 0.2618\n",
            "20/30 - Train loss: 0.9240, Val loss: 1.1102, Train dice: 0.3019, Val dice: 0.2609\n",
            "21/30 - Train loss: 0.9173, Val loss: 1.0885, Train dice: 0.3026, Val dice: 0.2627\n",
            "22/30 - Train loss: 0.9090, Val loss: 1.0881, Train dice: 0.3035, Val dice: 0.2668\n",
            "23/30 - Train loss: 0.9046, Val loss: 1.0953, Train dice: 0.3039, Val dice: 0.2575\n",
            "24/30 - Train loss: 0.8982, Val loss: 1.0916, Train dice: 0.3049, Val dice: 0.2663\n",
            "25/30 - Train loss: 0.8930, Val loss: 1.0950, Train dice: 0.3063, Val dice: 0.2534\n",
            "26/30 - Train loss: 0.8916, Val loss: 1.0930, Train dice: 0.3049, Val dice: 0.2652\n",
            "27/30 - Train loss: 0.8865, Val loss: 1.0970, Train dice: 0.3069, Val dice: 0.2526\n",
            "28/30 - Train loss: 0.8867, Val loss: 1.0829, Train dice: 0.3052, Val dice: 0.2680\n",
            "29/30 - Train loss: 0.8823, Val loss: 1.1427, Train dice: 0.3072, Val dice: 0.2327\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "\n",
        "train_loss_prt, train_dice_coefficient_prt = [], []\n",
        "val_loss_prt, val_dice_coefficient_prt = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    losses, dice_coefficients = train_one_epoch(dataloaders, model, criterion, optimizer, DEVICE)\n",
        "    train_loss_prt.append(losses[\"train\"])\n",
        "    val_loss_prt.append(losses[\"val\"])\n",
        "    train_dice_coefficient_prt.append(dice_coefficients[\"train\"])\n",
        "    val_dice_coefficient_prt.append(dice_coefficients[\"val\"])\n",
        "    \n",
        "    print(f\"{epoch}/{num_epochs} - Train loss: {losses['train']:.4f}, Val loss: {losses['val']:.4f},\" + \\\n",
        "          f\" Train dice: {dice_coefficients['train']:.4f}, Val dice: {dice_coefficients['val']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c93bd77",
      "metadata": {
        "id": "4c93bd77"
      },
      "source": [
        "### 5-3. Weight transfer with freezing encoder layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee79c39d",
      "metadata": {
        "id": "ee79c39d"
      },
      "outputs": [],
      "source": [
        "data_dir = \"../DATASET/Segmentation/\"\n",
        "is_cuda = True\n",
        "\n",
        "NUM_CLASSES = 4\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 12\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() and is_cuda else 'cpu')\n",
        "\n",
        "dataloaders = build_dataloader(data_dir, batch_size=BATCH_SIZE)\n",
        "model = UNet(num_classes=NUM_CLASSES, pretrained=True)\n",
        "model = model.to(DEVICE)\n",
        "model.encoder.requires_grad_ = False\n",
        "criterion = UNet_metric(num_classes=NUM_CLASSES)\n",
        "optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83e8040b",
      "metadata": {
        "id": "83e8040b",
        "outputId": "99ae3520-adfa-413b-d07d-b8ad8adb8b9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0/30 - Train loss: 2.4897, Val loss: 2.5063, Train dice: 0.0813, Val dice: 0.0721\n",
            "1/30 - Train loss: 2.1744, Val loss: 2.3675, Train dice: 0.0570, Val dice: 0.0240\n",
            "2/30 - Train loss: 1.9315, Val loss: 2.1080, Train dice: 0.0097, Val dice: 0.0004\n",
            "3/30 - Train loss: 1.7786, Val loss: 1.8504, Train dice: 0.0004, Val dice: 0.0000\n",
            "4/30 - Train loss: 1.6900, Val loss: 1.7040, Train dice: 0.0001, Val dice: 0.0000\n",
            "5/30 - Train loss: 1.6262, Val loss: 1.6337, Train dice: 0.0001, Val dice: 0.0000\n",
            "6/30 - Train loss: 1.5659, Val loss: 1.6002, Train dice: 0.0011, Val dice: 0.0000\n",
            "7/30 - Train loss: 1.4834, Val loss: 1.5592, Train dice: 0.0232, Val dice: 0.0004\n",
            "8/30 - Train loss: 1.3156, Val loss: 1.5181, Train dice: 0.1378, Val dice: 0.0162\n",
            "9/30 - Train loss: 1.1778, Val loss: 1.4137, Train dice: 0.2340, Val dice: 0.0918\n",
            "10/30 - Train loss: 1.1039, Val loss: 1.3173, Train dice: 0.2705, Val dice: 0.1654\n",
            "11/30 - Train loss: 1.0575, Val loss: 1.2599, Train dice: 0.2862, Val dice: 0.2039\n",
            "12/30 - Train loss: 1.0244, Val loss: 1.2177, Train dice: 0.2938, Val dice: 0.2245\n",
            "13/30 - Train loss: 0.9994, Val loss: 1.1978, Train dice: 0.2978, Val dice: 0.2313\n",
            "14/30 - Train loss: 0.9807, Val loss: 1.1877, Train dice: 0.2996, Val dice: 0.2364\n",
            "15/30 - Train loss: 0.9665, Val loss: 1.1727, Train dice: 0.3004, Val dice: 0.2398\n",
            "16/30 - Train loss: 0.9522, Val loss: 1.1620, Train dice: 0.3019, Val dice: 0.2440\n",
            "17/30 - Train loss: 0.9435, Val loss: 1.1690, Train dice: 0.3022, Val dice: 0.2338\n",
            "18/30 - Train loss: 0.9384, Val loss: 1.1325, Train dice: 0.3010, Val dice: 0.2528\n",
            "19/30 - Train loss: 0.9255, Val loss: 1.1562, Train dice: 0.3036, Val dice: 0.2461\n",
            "20/30 - Train loss: 0.9214, Val loss: 1.1569, Train dice: 0.3036, Val dice: 0.2405\n",
            "21/30 - Train loss: 0.9125, Val loss: 1.1248, Train dice: 0.3041, Val dice: 0.2549\n",
            "22/30 - Train loss: 0.9049, Val loss: 1.1160, Train dice: 0.3062, Val dice: 0.2544\n",
            "23/30 - Train loss: 0.9012, Val loss: 1.1256, Train dice: 0.3060, Val dice: 0.2528\n",
            "24/30 - Train loss: 0.8974, Val loss: 1.1115, Train dice: 0.3067, Val dice: 0.2549\n",
            "25/30 - Train loss: 0.8954, Val loss: 1.1108, Train dice: 0.3057, Val dice: 0.2575\n",
            "26/30 - Train loss: 0.8886, Val loss: 1.1061, Train dice: 0.3077, Val dice: 0.2575\n",
            "27/30 - Train loss: 0.8854, Val loss: 1.1081, Train dice: 0.3080, Val dice: 0.2574\n",
            "28/30 - Train loss: 0.8822, Val loss: 1.1019, Train dice: 0.3085, Val dice: 0.2587\n",
            "29/30 - Train loss: 0.8798, Val loss: 1.1060, Train dice: 0.3087, Val dice: 0.2577\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "\n",
        "train_loss_frz, train_dice_coefficient_frz = [], []\n",
        "val_loss_frz, val_dice_coefficient_frz = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    losses, dice_coefficients = train_one_epoch(dataloaders, model, criterion, optimizer, DEVICE)\n",
        "    train_loss_frz.append(losses[\"train\"])\n",
        "    val_loss_frz.append(losses[\"val\"])\n",
        "    train_dice_coefficient_frz.append(dice_coefficients[\"train\"])\n",
        "    val_dice_coefficient_frz.append(dice_coefficients[\"val\"])\n",
        "    \n",
        "    print(f\"{epoch}/{num_epochs} - Train loss: {losses['train']:.4f}, Val loss: {losses['val']:.4f},\" + \\\n",
        "          f\" Train dice: {dice_coefficients['train']:.4f}, Val dice: {dice_coefficients['val']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc9413a6",
      "metadata": {
        "id": "cc9413a6"
      },
      "source": [
        "![loss_figure-2.png](attachment:loss_figure-2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11f3cb4e",
      "metadata": {
        "id": "11f3cb4e"
      },
      "source": [
        "### 5-4. (Open Question) What if weight transfer with freezing \"decoder\" layer ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab30e7ea",
      "metadata": {
        "id": "ab30e7ea"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}